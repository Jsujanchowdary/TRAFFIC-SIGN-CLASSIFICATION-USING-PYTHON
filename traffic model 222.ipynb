{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1007ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp39-cp39-win_amd64.whl (167.2 MB)\n",
      "     ------------------------------------- 167.2/167.2 MB 10.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\j sujan chowdary\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2137df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.0-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\j sujan chowdary\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: torch==1.13.0 in c:\\users\\j sujan chowdary\\anaconda3\\lib\\site-packages (from torchvision) (1.13.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\j sujan chowdary\\anaconda3\\lib\\site-packages (from torchvision) (4.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\j sujan chowdary\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\j sujan chowdary\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\j sujan chowdary\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\j sujan chowdary\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\j sujan chowdary\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\j sujan chowdary\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0cd911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import here\n",
    "import os\n",
    "import PIL\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torch.utils.data.sampler as sampler\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbdd58f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = r\"C:\\Users\\j sujan chowdary\\Downloads\\traffic-signs-data\\train.p\"\n",
    "validation_file=r\"C:\\Users\\j sujan chowdary\\Downloads\\traffic-signs-data\\valid.p\"\n",
    "testing_file =r\"C:\\Users\\j sujan chowdary\\Downloads\\traffic-signs-data\\test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed7632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "# Number of training examples\n",
    "n_train = len(X_train)\n",
    "# Number of validation examples.\n",
    "n_valid = len(X_valid)\n",
    "# Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "\n",
    "# The shape of an traffic sign image\n",
    "image_shape = X_train[0].shape[:-1]\n",
    "\n",
    "# Number of unique classes/labels in the dataset.\n",
    "n_classes = len(set(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_valid)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da04ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data exploration visualization.\n",
    "class PickledDataset(Dataset):\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        with open(file_path, mode='rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.features = data['features']\n",
    "            self.labels = data['labels']\n",
    "            self.count = len(self.labels)\n",
    "            self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        feature = self.features[index]\n",
    "        if self.transform is not None:\n",
    "            feature = self.transform(feature)\n",
    "        return (feature, self.labels[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41425ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60b4fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineNet(nn.Module):\n",
    "    def __init__(self, gray=False):\n",
    "        super(BaselineNet, self).__init__()\n",
    "        input_chan = 1 if gray else 3\n",
    "        self.conv1 = nn.Conv2d(input_chan, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bc087f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17229e6cd30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc026ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PickledDataset(training_file, transform=transforms.ToTensor())\n",
    "valid_dataset = PickledDataset(validation_file, transform=transforms.ToTensor())\n",
    "test_dataset = PickledDataset(testing_file, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aa8cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def to_device(x, y):\n",
    "    return x.to(device), y.to(device, dtype=torch.int64)\n",
    "\n",
    "train_loader = WrappedDataLoader(train_loader, to_device)\n",
    "valid_loader = WrappedDataLoader(valid_loader, to_device)\n",
    "test_loader = WrappedDataLoader(test_loader, to_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "414865d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aec1a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, x, y, opt=None):\n",
    "    loss = loss_func(model(x), y)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "555d2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_batch(model, loss_func, x, y):\n",
    "    output = model(x)\n",
    "    loss = loss_func(output, y)\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    correct = pred == y.view(*pred.shape)\n",
    "    \n",
    "    return loss.item(), torch.sum(correct).item(), len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67e11a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        # Train model\n",
    "        model.train()\n",
    "        losses, nums = zip(*[loss_batch(model, loss_func, x, y, opt) for x, y in train_dl])\n",
    "        train_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        # Validation model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, corrects, nums = zip(*[valid_batch(model, loss_func, x, y) for x, y in valid_dl])\n",
    "            valid_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "            valid_accuracy = np.sum(corrects) / np.sum(nums) * 100\n",
    "            print(f\"[Epoch {epoch+1}/{epochs}] \"\n",
    "                  f\"Train loss: {train_loss:.6f}\\t\"\n",
    "                  f\"Validation loss: {valid_loss:.6f}\\t\",\n",
    "                  f\"Validation accruacy: {valid_accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d15b6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_func, dl):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses, corrects, nums = zip(*[valid_batch(model, loss_func, x, y) for x, y in dl])\n",
    "        test_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        test_accuracy = np.sum(corrects) / np.sum(nums) * 100\n",
    "        \n",
    "    print(f\"Test loss: {test_loss:.6f}\\t\"\n",
    "          f\"Test accruacy: {test_accuracy:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c52d3c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/20] Train loss: 3.676078\tValidation loss: 3.598334\t Validation accruacy: 4.989%\n",
      "[Epoch 2/20] Train loss: 3.485083\tValidation loss: 3.575863\t Validation accruacy: 5.442%\n",
      "[Epoch 3/20] Train loss: 3.455797\tValidation loss: 3.527243\t Validation accruacy: 7.324%\n",
      "[Epoch 4/20] Train loss: 3.335641\tValidation loss: 3.300606\t Validation accruacy: 19.002%\n",
      "[Epoch 5/20] Train loss: 2.683471\tValidation loss: 2.313919\t Validation accruacy: 39.002%\n",
      "[Epoch 6/20] Train loss: 1.698090\tValidation loss: 1.572484\t Validation accruacy: 56.259%\n",
      "[Epoch 7/20] Train loss: 1.127079\tValidation loss: 1.217454\t Validation accruacy: 64.785%\n",
      "[Epoch 8/20] Train loss: 0.830324\tValidation loss: 0.932193\t Validation accruacy: 72.744%\n",
      "[Epoch 9/20] Train loss: 0.653855\tValidation loss: 0.890009\t Validation accruacy: 74.921%\n",
      "[Epoch 10/20] Train loss: 0.546850\tValidation loss: 0.746248\t Validation accruacy: 79.524%\n",
      "[Epoch 11/20] Train loss: 0.461076\tValidation loss: 0.724026\t Validation accruacy: 80.794%\n",
      "[Epoch 12/20] Train loss: 0.396648\tValidation loss: 0.638646\t Validation accruacy: 82.789%\n",
      "[Epoch 13/20] Train loss: 0.351077\tValidation loss: 0.657836\t Validation accruacy: 82.812%\n",
      "[Epoch 14/20] Train loss: 0.306476\tValidation loss: 0.701309\t Validation accruacy: 81.973%\n",
      "[Epoch 15/20] Train loss: 0.275740\tValidation loss: 0.637847\t Validation accruacy: 83.787%\n",
      "[Epoch 16/20] Train loss: 0.243603\tValidation loss: 0.643136\t Validation accruacy: 83.016%\n",
      "[Epoch 17/20] Train loss: 0.220301\tValidation loss: 0.691144\t Validation accruacy: 82.698%\n",
      "[Epoch 18/20] Train loss: 0.197457\tValidation loss: 0.661467\t Validation accruacy: 84.558%\n",
      "[Epoch 19/20] Train loss: 0.183578\tValidation loss: 0.591463\t Validation accruacy: 85.646%\n",
      "[Epoch 20/20] Train loss: 0.159200\tValidation loss: 0.629816\t Validation accruacy: 85.170%\n",
      "Test loss: 0.935812\tTest accruacy: 85.194%\n"
     ]
    }
   ],
   "source": [
    "fit(n_epochs, model, criterion, optimizer, train_loader, valid_loader)\n",
    "evaluate(model, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62a5b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLAHE_GRAY:\n",
    "    def __init__(self, clipLimit=2.5, tileGridSize=(4, 4)):\n",
    "        self.clipLimit = clipLimit\n",
    "        self.tileGridSize = tileGridSize\n",
    "\n",
    "    def __call__(self, im):\n",
    "        img_y = cv2.cvtColor(im, cv2.COLOR_RGB2YCrCb)[:,:,0]\n",
    "        clahe = cv2.createCLAHE(clipLimit=self.clipLimit, tileGridSize=self.tileGridSize)\n",
    "        img_y = clahe.apply(img_y)\n",
    "        img_output = img_y.reshape(img_y.shape + (1,))\n",
    "        return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0424748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    CLAHE_GRAY(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = PickledDataset(training_file, transform=data_transforms)\n",
    "valid_dataset = PickledDataset(validation_file, transform=data_transforms)\n",
    "test_dataset = PickledDataset(testing_file, transform=data_transforms)\n",
    "\n",
    "train_loader = WrappedDataLoader(DataLoader(train_dataset, batch_size=64, shuffle=True), to_device)\n",
    "valid_loader = WrappedDataLoader(DataLoader(valid_dataset, batch_size=64, shuffle=False), to_device)\n",
    "test_loader = WrappedDataLoader(DataLoader(test_dataset, batch_size=64, shuffle=False), to_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef777326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/20] Train loss: 3.722894\tValidation loss: 3.683751\t Validation accruacy: 3.401%\n",
      "[Epoch 2/20] Train loss: 3.524601\tValidation loss: 3.562498\t Validation accruacy: 6.803%\n",
      "[Epoch 3/20] Train loss: 3.455149\tValidation loss: 3.524208\t Validation accruacy: 5.737%\n",
      "[Epoch 4/20] Train loss: 3.331840\tValidation loss: 3.221627\t Validation accruacy: 22.494%\n",
      "[Epoch 5/20] Train loss: 2.430014\tValidation loss: 1.875487\t Validation accruacy: 48.299%\n",
      "[Epoch 6/20] Train loss: 1.336981\tValidation loss: 1.112125\t Validation accruacy: 67.211%\n",
      "[Epoch 7/20] Train loss: 0.879377\tValidation loss: 0.800699\t Validation accruacy: 75.986%\n",
      "[Epoch 8/20] Train loss: 0.683765\tValidation loss: 0.669834\t Validation accruacy: 80.000%\n",
      "[Epoch 9/20] Train loss: 0.552878\tValidation loss: 0.591165\t Validation accruacy: 82.200%\n",
      "[Epoch 10/20] Train loss: 0.458593\tValidation loss: 0.516431\t Validation accruacy: 85.057%\n",
      "[Epoch 11/20] Train loss: 0.393966\tValidation loss: 0.433600\t Validation accruacy: 88.073%\n",
      "[Epoch 12/20] Train loss: 0.343410\tValidation loss: 0.453569\t Validation accruacy: 86.236%\n",
      "[Epoch 13/20] Train loss: 0.299695\tValidation loss: 0.383364\t Validation accruacy: 89.388%\n",
      "[Epoch 14/20] Train loss: 0.264017\tValidation loss: 0.363935\t Validation accruacy: 90.340%\n",
      "[Epoch 15/20] Train loss: 0.234741\tValidation loss: 0.339013\t Validation accruacy: 90.431%\n",
      "[Epoch 16/20] Train loss: 0.207323\tValidation loss: 0.326907\t Validation accruacy: 90.998%\n",
      "[Epoch 17/20] Train loss: 0.183054\tValidation loss: 0.339434\t Validation accruacy: 90.340%\n",
      "[Epoch 18/20] Train loss: 0.166769\tValidation loss: 0.304081\t Validation accruacy: 91.701%\n",
      "[Epoch 19/20] Train loss: 0.151253\tValidation loss: 0.309489\t Validation accruacy: 91.111%\n",
      "[Epoch 20/20] Train loss: 0.135084\tValidation loss: 0.308151\t Validation accruacy: 91.565%\n",
      "Test loss: 0.606284\tTest accruacy: 88.187%\n"
     ]
    }
   ],
   "source": [
    "model = BaselineNet(gray=True).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "fit(n_epochs, model, criterion, optimizer, train_loader, valid_loader)\n",
    "evaluate(model, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f3ef05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path):\n",
    "    if not os.path.exists(f\"{path}/train_gray.p\"):\n",
    "        for dataset in ['train', 'valid', 'test']:\n",
    "            with open(f\"{path}/{dataset}.p\", mode='rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                X = data['features']\n",
    "                y = data['labels']\n",
    "\n",
    "            clahe = CLAHE_GRAY()\n",
    "            for i in range(len(X)):\n",
    "                X[i] = clahe(X[i])\n",
    "\n",
    "            X = X[:, :, :, 0]\n",
    "            with open(f\"{path}/{dataset}_gray.p\", \"wb\") as f:\n",
    "                pickle.dump({\"features\": X.reshape(\n",
    "                    X.shape + (1,)), \"labels\": y}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ea5f72f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'traffic-signs-data/train.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14552\\1939484718.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'traffic-signs-data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtraining_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'train_gray.p'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvalidation_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data/valid_gray.p\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtesting_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data/test_gray.p\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14552\\2920422739.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{path}/train_gray.p\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{path}/{dataset}.p\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'traffic-signs-data/train.p'"
     ]
    }
   ],
   "source": [
    "preprocess('data')\n",
    "training_file = 'data/train_gray.p'\n",
    "validation_file = \"data/valid_gray.p\"\n",
    "testing_file = \"data/test_gray.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d7cfc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PickledDataset(training_file, transform=transforms.ToTensor())\n",
    "valid_dataset = PickledDataset(validation_file, transform=transforms.ToTensor())\n",
    "test_dataset = PickledDataset(testing_file, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = WrappedDataLoader(DataLoader(train_dataset, batch_size=64, shuffle=True), to_device)\n",
    "valid_loader = WrappedDataLoader(DataLoader(valid_dataset, batch_size=64, shuffle=False), to_device)\n",
    "test_loader = WrappedDataLoader(DataLoader(test_dataset, batch_size=64, shuffle=False), to_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53782764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_dataset(dataset):\n",
    "    X = dataset.features\n",
    "    y = dataset.labels\n",
    "    num_classes = 43\n",
    "    \n",
    "    X_extended = np.empty([0] + list(dataset.features.shape)[1:], dtype=dataset.features.dtype)\n",
    "    y_extended = np.empty([0], dtype = dataset.labels.dtype)\n",
    "    \n",
    "    horizontally_flippable = [11, 12, 13, 15, 17, 18, 22, 26, 30, 35]\n",
    "    vertically_flippable = [1, 5, 12, 15, 17]\n",
    "    both_flippable = [32, 40]\n",
    "    cross_flippable = np.array([\n",
    "        [19, 20],\n",
    "        [33, 34],\n",
    "        [36, 37],\n",
    "        [38, 39],\n",
    "        [20, 19],\n",
    "        [34, 33],\n",
    "        [37, 36],\n",
    "        [39, 38]\n",
    "    ])\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        X_extended = np.append(X_extended, X[y==c], axis=0)  \n",
    "        \n",
    "        if c in horizontally_flippable:\n",
    "            X_extended = np.append(X_extended, X[y==c][:,:,::-1,:], axis=0)\n",
    "        if c in vertically_flippable:\n",
    "            X_extended = np.append(X_extended, X[y==c][:,::-1,:,:], axis=0)\n",
    "        if c in cross_flippable[:,0]:\n",
    "            flip_c = cross_flippable[cross_flippable[:,0]==c][0][1]\n",
    "            X_extended = np.append(X_extended, X[y==flip_c][:,:,::-1,:], axis=0)\n",
    "        if c in both_flippable:\n",
    "            X_extended = np.append(X_extended, X[y==c][:,::-1,::-1,:], axis=0)\n",
    "        \n",
    "        y_extended = np.append(y_extended, np.full(X_extended.shape[0]-y_extended.shape[0], c, dtype=y_extended.dtype))\n",
    "    \n",
    "    dataset.features = X_extended\n",
    "    dataset.labels = y_extended\n",
    "    dataset.count = len(y_extended)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "618347b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = extend_dataset(train_dataset)\n",
    "train_loader = WrappedDataLoader(DataLoader(train_dataset, batch_size=64, shuffle=True), to_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5700333",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [6, 1, 5, 5], expected input[64, 3, 32, 32] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14552\\2356221038.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBaselineNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14552\\4254717771.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, model, loss_func, opt, train_dl, valid_dl)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;31m# Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Validation model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14552\\4254717771.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;31m# Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Validation model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14552\\2733330892.py\u001b[0m in \u001b[0;36mloss_batch\u001b[1;34m(model, loss_func, x, y, opt)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14552\\322919690.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 459\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [6, 1, 5, 5], expected input[64, 3, 32, 32] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "model = BaselineNet(gray=True).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "fit(n_epochs, model, criterion, optimizer, train_loader, valid_loader)\n",
    "evaluate(model, criterion, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676597c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = extend_dataset(PickledDataset(training_file))\n",
    "\n",
    "class_sample_count = np.bincount(train_dataset.labels)\n",
    "weights = 1 / np.array([class_sample_count[y] for y in train_dataset.labels])\n",
    "samp = sampler.WeightedRandomSampler(weights, 43 * 20000)\n",
    "\n",
    "train_loader = WrappedDataLoader(DataLoader(train_dataset, batch_size=64, sampler=samp), to_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384519c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_y_train = torch.LongTensor([]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _, y in train_loader:\n",
    "        balanced_y_train = torch.cat((balanced_y_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340db84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomRotation(20, resample=PIL.Image.BICUBIC),\n",
    "        transforms.RandomAffine(0, translate=(0.2, 0.2), resample=PIL.Image.BICUBIC),\n",
    "        transforms.RandomAffine(0, shear=20, resample=PIL.Image.BICUBIC),\n",
    "        transforms.RandomAffine(0, scale=(0.8, 1.2), resample=PIL.Image.BICUBIC)\n",
    "    ]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_data_transforms = transforms.ToTensor()\n",
    "\n",
    "train_dataset = extend_dataset(PickledDataset(training_file, transform=train_data_transforms))\n",
    "valid_dataset = PickledDataset(validation_file, transform=test_data_transforms)\n",
    "test_dataset = PickledDataset(testing_file, transform=test_data_transforms)\n",
    "\n",
    "train_loader = WrappedDataLoader(DataLoader(train_dataset, batch_size=64, sampler=samp), to_device)\n",
    "valid_loader = WrappedDataLoader(DataLoader(valid_dataset, batch_size=64, shuffle=False), to_device)\n",
    "test_loader = WrappedDataLoader(DataLoader(test_dataset, batch_size=64, shuffle=False), to_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca79aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_np(img):\n",
    "    img = img.numpy().transpose((1, 2, 0)).squeeze()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineNet(gray=True).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "fit(n_epochs, model, criterion, optimizer, train_loader, valid_loader)\n",
    "evaluate(model, criterion, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TrafficSignNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 100, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(100)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(100, 150, 3)\n",
    "        self.conv2_bn = nn.BatchNorm2d(150)\n",
    "        self.conv3 = nn.Conv2d(150, 250, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(250)\n",
    "        self.fc1 = nn.Linear(250 * 3 * 3, 350)\n",
    "        self.fc1_bn = nn.BatchNorm1d(350)\n",
    "        self.fc2 = nn.Linear(350, 43)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.elu(self.conv1(x)))\n",
    "        x = self.dropout(self.conv1_bn(x))\n",
    "        x = self.pool(F.elu(self.conv2(x)))\n",
    "        x = self.dropout(self.conv2_bn(x))\n",
    "        x = self.pool(F.elu(self.conv3(x)))\n",
    "        x = self.dropout(self.conv3_bn(x))\n",
    "        x = x.view(-1, 250 * 3 * 3)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = self.dropout(self.fc1_bn(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929800be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl, patience=10):\n",
    "    wait = 0\n",
    "    valid_loss_min = np.Inf\n",
    "    for epoch in range(epochs):\n",
    "        # Train model\n",
    "        model.train()\n",
    "        losses, nums = zip(*[loss_batch(model, loss_func, x, y, opt) for x, y in train_dl])\n",
    "        train_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        # Validation model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, corrects, nums = zip(*[valid_batch(model, loss_func, x, y) for x, y in valid_dl])\n",
    "            valid_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "            valid_accuracy = np.sum(corrects) / np.sum(nums) * 100\n",
    "            print(f\"[Epoch {epoch+1}/{epochs}] \"\n",
    "                  f\"Train loss: {train_loss:.6f}\\t\"\n",
    "                  f\"Validation loss: {valid_loss:.6f}\\t\",\n",
    "                  f\"Validation accruacy: {valid_accuracy:.3f}%\")\n",
    "            # Save model if validation loss has decreased\n",
    "            if valid_loss <= valid_loss_min:\n",
    "                print(f\"Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...\")\n",
    "                torch.save(model.state_dict(), 'model.pt')\n",
    "                valid_loss_min = valid_loss\n",
    "                wait = 0\n",
    "            # Early stopping\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= patience:\n",
    "                    print(f\"Terminated Training for Early Stopping at Epoch {epoch+1}\")\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38cbf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "model = TrafficSignNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "fit(n_epochs, model, criterion, optimizer, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae1f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = torch.load('model.pt', map_location=device)\n",
    "model.load_state_dict(check_point)\n",
    "evaluate(model, criterion, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9854982",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Stn, self).__init__()\n",
    "        # Spatial transformer localization-network\n",
    "        self.loc_net = nn.Sequential(\n",
    "            nn.Conv2d(1, 50, 7),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(50, 100, 5),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(100 * 4 * 4, 100),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(100, 3 * 2)\n",
    "        )\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xs = self.loc_net(x)\n",
    "        xs = xs.view(-1, 100 * 4 * 4)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TrafficSignNet, self).__init__()\n",
    "        self.stn = Stn()\n",
    "        self.conv1 = nn.Conv2d(1, 100, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(100)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(100, 150, 3)\n",
    "        self.conv2_bn = nn.BatchNorm2d(150)\n",
    "        self.conv3 = nn.Conv2d(150, 250, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(250)\n",
    "        self.fc1 = nn.Linear(250 * 3 * 3, 350)\n",
    "        self.fc1_bn = nn.BatchNorm1d(350)\n",
    "        self.fc2 = nn.Linear(350, 43)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stn(x)\n",
    "        x = self.pool(F.elu(self.conv1(x)))\n",
    "        x = self.dropout(self.conv1_bn(x))\n",
    "        x = self.pool(F.elu(self.conv2(x)))\n",
    "        x = self.dropout(self.conv2_bn(x))\n",
    "        x = self.pool(F.elu(self.conv3(x)))\n",
    "        x = self.dropout(self.conv3_bn(x))\n",
    "        x = x.view(-1, 250 * 3 * 3)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = self.dropout(self.fc1_bn(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de136280",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrafficSignNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "fit(n_epochs, model, criterion, optimizer, train_loader, valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a939fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = torch.load('model.pt', map_location=device)\n",
    "model.load_state_dict(check_point)\n",
    "evaluate(model, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95267782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e8220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e346e6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8581b4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451bb522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e45af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
